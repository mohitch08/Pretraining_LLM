{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2a8fff-4124-4c6d-9258-c05657ec01c8",
   "metadata": {},
   "source": [
    "# . Model evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31fbf66-c7d5-4323-8f8a-acda7a12f66b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#!pip install -U git+https://github.com/EleutherAI/lm-evaluation-harness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b1cfc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c2c258-98de-43c7-9b96-cce7a6f20024",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-19:08:43:08,774 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2025-04-19:08:43:08,817 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2025-04-19:08:43:16,202 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-04-19:08:43:16,203 INFO     [__main__.py:376] Selected Tasks: ['truthfulqa_mc2']\n",
      "2025-04-19:08:43:16,207 INFO     [evaluator.py:158] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2025-04-19:08:43:16,207 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': './models/TinySolar-248m-4k'}\n",
      "2025-04-19:08:43:16,210 INFO     [huggingface.py:130] Using device 'cpu'\n",
      "2025-04-19:08:43:16,468 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cpu'}\n",
      "Downloading readme: 100%|██████████████████| 9.59k/9.59k [00:00<00:00, 37.6MB/s]\n",
      "Downloading data: 100%|███████████████████████| 271k/271k [00:00<00:00, 830kB/s]\n",
      "Generating validation split: 100%|██| 817/817 [00:00<00:00, 23148.53 examples/s]\n",
      "2025-04-19:08:43:25,719 INFO     [evaluator.py:274] Setting fewshot random generator seed to 1234\n",
      "2025-04-19:08:43:25,721 INFO     [task.py:423] Building contexts for truthfulqa_mc2 on rank 0...\n",
      "100%|███████████████████████████████████████████| 5/5 [00:00<00:00, 1060.02it/s]\n",
      "2025-04-19:08:43:25,727 INFO     [evaluator.py:457] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|███████████| 33/33 [00:05<00:00,  6.38it/s]\n",
      "2025-04-19:08:43:30,919 WARNING  [huggingface.py:1341] Failed to get model SHA for ./models/TinySolar-248m-4k at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models/TinySolar-248m-4k'. Use `repo_type` argument if needed.\n",
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "2025-04-19:08:43:33,242 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=./models/TinySolar-248m-4k), gen_kwargs: (None), limit: 5.0, num_fewshot: None, batch_size: 1\n",
      "|    Tasks     |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|--------------|------:|------|-----:|------|---|-----:|---|-----:|\n",
      "|truthfulqa_mc2|      2|none  |     0|acc   |↑  |0.4007|±  |0.2446|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=./models/TinySolar-248m-4k \\\n",
    "    --tasks truthfulqa_mc2 \\\n",
    "    --device cpu \\\n",
    "    --limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc097be-7dbb-4a90-a954-f39d30e8e52c",
   "metadata": {
    "height": 404
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19:08:43:37,621 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2025-04-19:08:43:37,649 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2025-04-19:08:43:41,635 INFO     [__main__.py:376] Selected Tasks: ['arc_challenge']\n",
      "2025-04-19:08:43:41,635 INFO     [evaluator.py:158] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2025-04-19:08:43:41,636 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': 'YOUR_MODEL'}\n",
      "2025-04-19:08:43:41,637 INFO     [huggingface.py:130] Using device 'cpu'\n",
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 385, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1325, in _hf_hub_download_to_cache_dir\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1823, in _raise_on_head_call_error\n",
      "    raise head_call_error\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1722, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(url=url, proxies=proxies, timeout=etag_timeout, headers=headers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1645, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 372, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 396, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 352, in hf_raise_for_status\n",
      "    raise RepositoryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-6803623d-7829b43472efedc02c5b3a39;683d873f-8732-4ea7-8b0c-ccb7d12f1c38)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "Invalid username or password.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/__main__.py\", line 382, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/utils.py\", line 397, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 198, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/api/model.py\", line 147, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 161, in __init__\n",
      "    self._get_config(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 505, in _get_config\n",
      "    self._config = transformers.AutoConfig.from_pretrained(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1100, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 634, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 406, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: YOUR_MODEL is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
      "2025-04-19:08:43:45,451 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2025-04-19:08:43:45,479 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2025-04-19:08:43:49,388 INFO     [__main__.py:376] Selected Tasks: ['hellaswag']\n",
      "2025-04-19:08:43:49,389 INFO     [evaluator.py:158] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2025-04-19:08:43:49,389 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': 'YOUR_MODEL'}\n",
      "2025-04-19:08:43:49,391 INFO     [huggingface.py:130] Using device 'cpu'\n",
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 385, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1325, in _hf_hub_download_to_cache_dir\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1823, in _raise_on_head_call_error\n",
      "    raise head_call_error\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1722, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(url=url, proxies=proxies, timeout=etag_timeout, headers=headers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1645, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 372, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 396, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 352, in hf_raise_for_status\n",
      "    raise RepositoryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-68036245-18d3ceb5193842cf3c4f1b11;624de908-7ba1-4673-9b32-b64cf25fe127)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "Invalid username or password.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/__main__.py\", line 382, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/utils.py\", line 397, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 198, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/api/model.py\", line 147, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 161, in __init__\n",
      "    self._get_config(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 505, in _get_config\n",
      "    self._config = transformers.AutoConfig.from_pretrained(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1100, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 634, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 406, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: YOUR_MODEL is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19:08:43:53,166 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2025-04-19:08:43:53,194 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2025-04-19:08:43:57,192 INFO     [__main__.py:376] Selected Tasks: ['mmlu']\n",
      "2025-04-19:08:43:57,193 INFO     [evaluator.py:158] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2025-04-19:08:43:57,193 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': 'YOUR_MODEL'}\n",
      "2025-04-19:08:43:57,195 INFO     [huggingface.py:130] Using device 'cpu'\n",
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 385, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1325, in _hf_hub_download_to_cache_dir\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1823, in _raise_on_head_call_error\n",
      "    raise head_call_error\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1722, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(url=url, proxies=proxies, timeout=etag_timeout, headers=headers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1645, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 372, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 396, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 352, in hf_raise_for_status\n",
      "    raise RepositoryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-6803624d-1e73ff764d41b0ed411e4cf0;cbd7d59d-f0ea-49fb-811a-a525958244f1)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "Invalid username or password.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/__main__.py\", line 382, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/utils.py\", line 397, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 198, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/api/model.py\", line 147, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 161, in __init__\n",
      "    self._get_config(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 505, in _get_config\n",
      "    self._config = transformers.AutoConfig.from_pretrained(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1100, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 634, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 406, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: YOUR_MODEL is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
      "2025-04-19:08:44:00,940 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2025-04-19:08:44:00,968 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2025-04-19:08:44:05,185 INFO     [__main__.py:376] Selected Tasks: ['truthfulqa_mc2']\n",
      "2025-04-19:08:44:05,185 INFO     [evaluator.py:158] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2025-04-19:08:44:05,185 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': 'YOUR_MODEL'}\n",
      "2025-04-19:08:44:05,187 INFO     [huggingface.py:130] Using device 'cpu'\n",
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 385, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1325, in _hf_hub_download_to_cache_dir\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1823, in _raise_on_head_call_error\n",
      "    raise head_call_error\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1722, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(url=url, proxies=proxies, timeout=etag_timeout, headers=headers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1645, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 372, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 396, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 352, in hf_raise_for_status\n",
      "    raise RepositoryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-68036255-07a7f9077f6c4141763a4b9f;c7b9e81a-bdef-414e-8c85-e7f5bfd4be62)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "Invalid username or password.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/__main__.py\", line 382, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/utils.py\", line 397, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 198, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/api/model.py\", line 147, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 161, in __init__\n",
      "    self._get_config(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 505, in _get_config\n",
      "    self._config = transformers.AutoConfig.from_pretrained(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1100, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 634, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 406, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: YOUR_MODEL is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19:08:44:09,045 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2025-04-19:08:44:09,074 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2025-04-19:08:44:13,031 INFO     [__main__.py:376] Selected Tasks: ['winogrande']\n",
      "2025-04-19:08:44:13,032 INFO     [evaluator.py:158] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2025-04-19:08:44:13,032 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': 'YOUR_MODEL'}\n",
      "2025-04-19:08:44:13,034 INFO     [huggingface.py:130] Using device 'cpu'\n",
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 385, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1325, in _hf_hub_download_to_cache_dir\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1823, in _raise_on_head_call_error\n",
      "    raise head_call_error\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1722, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(url=url, proxies=proxies, timeout=etag_timeout, headers=headers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1645, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 372, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 396, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 352, in hf_raise_for_status\n",
      "    raise RepositoryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-6803625d-3dbd159c0c16a6f9771532ad;46b7c583-e54e-40f1-8eea-71e34c314024)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "Invalid username or password.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/__main__.py\", line 382, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/utils.py\", line 397, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 198, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/api/model.py\", line 147, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 161, in __init__\n",
      "    self._get_config(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 505, in _get_config\n",
      "    self._config = transformers.AutoConfig.from_pretrained(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1100, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 634, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 406, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: YOUR_MODEL is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
      "2025-04-19:08:44:16,721 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2025-04-19:08:44:16,750 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.\n",
      "2025-04-19:08:44:20,688 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']\n",
      "2025-04-19:08:44:20,689 INFO     [evaluator.py:158] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2025-04-19:08:44:20,689 INFO     [evaluator.py:195] Initializing hf model, with arguments: {'pretrained': 'YOUR_MODEL'}\n",
      "2025-04-19:08:44:20,690 INFO     [huggingface.py:130] Using device 'cpu'\n",
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 385, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1325, in _hf_hub_download_to_cache_dir\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1823, in _raise_on_head_call_error\n",
      "    raise head_call_error\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1722, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(url=url, proxies=proxies, timeout=etag_timeout, headers=headers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1645, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 372, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 396, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py\", line 352, in hf_raise_for_status\n",
      "    raise RepositoryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-68036264-0bf397666e747e777db244ce;73d56547-6210-4060-8b11-04400e0f0059)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/YOUR_MODEL/resolve/main/config.json.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "Invalid username or password.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/__main__.py\", line 382, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/utils.py\", line 397, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 198, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/api/model.py\", line 147, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 161, in __init__\n",
      "    self._get_config(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 505, in _get_config\n",
      "    self._config = transformers.AutoConfig.from_pretrained(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1100, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 634, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py\", line 406, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: YOUR_MODEL is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def h6_open_llm_leaderboard(model_name):\n",
    "  task_and_shot = [\n",
    "      ('arc_challenge', 25),\n",
    "      ('hellaswag', 10),\n",
    "      ('mmlu', 5),\n",
    "      ('truthfulqa_mc2', 0),\n",
    "      ('winogrande', 5),\n",
    "      ('gsm8k', 5)\n",
    "  ]\n",
    "\n",
    "  for task, fewshot in task_and_shot:\n",
    "    eval_cmd = f\"\"\"\n",
    "    lm_eval --model hf \\\n",
    "        --model_args pretrained={model_name} \\\n",
    "        --tasks {task} \\\n",
    "        --device cpu \\\n",
    "        --num_fewshot {fewshot}\n",
    "    \"\"\"\n",
    "    os.system(eval_cmd)\n",
    "\n",
    "h6_open_llm_leaderboard(model_name=\"YOUR_MODEL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
